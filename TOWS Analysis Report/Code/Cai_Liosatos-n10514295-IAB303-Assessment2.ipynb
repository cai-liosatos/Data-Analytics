{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAB303 - Assessment Task 2\n",
    "## TOWS analysis report\n",
    "\n",
    "#### INSTRUCTIONS\n",
    "\n",
    "1. Complete the section below with your personal details (and run the cell)\n",
    "2. Choose to use either the supplied scenario OR your own scenario. If selecting your own, check suitability with teaching team. If using the supplied scenario, use the provided internal data. You may supplement this with additional data as required.\n",
    "3. Ensure that you include at least 1 complete analysis using *internal* data\n",
    "4. Ensure that you include at least 1 complete analysis using *external* data\n",
    "5. Ensure that you include at least 1 actionable recommendation from a TOWS analysis using your data analytics from steps 3 & 4.\n",
    "6. Ensure that you use markdown cells to document your thinking and decision making for each stage of the process. Be clear on how your decisions are working towards addressing the business concern.\n",
    "7. Ensure that you undertakee a peer review process and complete the peer review section\n",
    "6. Before handing in your notebook, clear all cell outputs and run the complete notebook. Ensure that it runs without errors and that all output is displaying\n",
    "7. Right-click on your notebook name (in file viewer) and select download. Ensure that your name and student ID are on the file, and then upload to the appropriate assignment upload link in blackboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the following cell with your details and run to produce your personalised header for this assignment\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "first_name = \"Cai\"\n",
    "last_name = \"Liosatos\"\n",
    "student_number = \"n10514295\"\n",
    "\n",
    "personal_header = \"<h1>\"+first_name+\" \"+last_name+\" (\"+student_number+\")</h1>\"\n",
    "display(HTML(personal_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed for this notebook here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "\n",
    "cache_on = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The client is a not-for-profit organisation offering residential aged care services within Brisbane. They are curious as to the most efficient spending strategy of recently accrued funding to you maximise their companies gains from said spending.  To complete this task, information regarding the following areas will be acquired and analysed: <br />\n",
    "-\tthe community’s understanding of the needs of the sector <br />\n",
    "-\tthe potential impact of government action <br />\n",
    "-\ttheir own influence sphere within the sector <br />\n",
    "\n",
    "This information is pertinent to our client as it provides them an insight as to potential areas they can improve internally, as well as potential external impacts dictating societies opinions and perspectives on the industry and any forthcoming outcomes from these. Cross correlating the internal and external insights provides our client with a road map for future improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Concern:\n",
    "The client is concerned about present factors in the sector they work in, and are wishing or an analysis to be conducted regarding a number of areas, as follows: <br />\n",
    "-\tthe community’s understanding of the needs of the sector <br />\n",
    "-\tthe potential impact of government action <br />\n",
    "-\ttheir own influence sphere within the sector <br />\n",
    "\n",
    "They want to wholly understand each of these three aspects and wish to enhance or improve these areas with their own company. They are also looking to analyse the strengths and weaknesses in their service area, and potential opportunities or threats from external factors that could affect them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stakeholders:\n",
    "\n",
    "The only directly relevant stakeholder to this analysis is the client themselves. However, parties such as the source of their newly acquired funding, legislative bodies, or other external parties interested in our client would also be classed as a stakeholder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "Through analysing external data from multiple sources (the guardian API, and anonymous survey from willing unrelated participants), what are some potential opportunities or threats that could impact our client either positively or negatively; and how and they be taken advantage of or remedied\n",
    "\n",
    "Through analysing data obtained internally (CSV containing reports of aged care facilities), what are some potential strengths or weaknesses impacting our client either positively or negatively; and how can they be taken advantage of or remedied\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create functions to complete repetitive code (in this case, caching API pulling and HTML scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions for caching API search results for local use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a cached file containing the page pulled from the API\n",
    "def cache_save(folder_url, current_page, cache_list):\n",
    "    np.save(folder_url+str(current_page)+\".npy\", cache_list, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "# function to load the cached files into a list\n",
    "def cache_load(folder_url):\n",
    "# loading cache\n",
    "    if os.path.exists(folder_url):\n",
    "        loaded_cache = []\n",
    "        for file in os.listdir(folder_url):\n",
    "            loaded_cache.append(np.load(folder_url+file, allow_pickle=True).tolist())\n",
    "        new_cache_list = flatten_list(loaded_cache)\n",
    "        return new_cache_list\n",
    "\n",
    "# function to flatten list of cached lists into a singular list\n",
    "def flatten_list(cache_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in cache_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the api URL to get the total page count\n",
    "def page_count(api_url_start, api_url_end):\n",
    "    error_counter = 0\n",
    "    while error_counter < 3:\n",
    "        api_url = api_url_start + \"1\" + api_url_end\n",
    "        content = requests.get(api_url)\n",
    "        api_data = json.loads(content.content)\n",
    "        if api_data['response']['status'] == \"ok\":\n",
    "            page_count = int(api_data['response']['pages'])\n",
    "            break\n",
    "        else:\n",
    "            error_counter += 1\n",
    "    page_count = \"API has errored three times in a row whilst trying to get page count, check if the URL is correct\" if error_counter >= 3 else page_count\n",
    "    return page_count\n",
    "\n",
    "#  function to scrape the data from the page returned from the api into a list\n",
    "def api_scraping(page_count, url_start, url_end, folder_url):\n",
    "    error_msg = []\n",
    "    error_counter = 0\n",
    "    current_page = 1\n",
    "    results_list = []\n",
    "# while loop to add outputs to a list\n",
    "    while current_page <= page_count:\n",
    "        if error_counter < 3:\n",
    "            cache_list = []\n",
    "            api_url = url_start + str(current_page) + url_end\n",
    "            content = requests.get(api_url)\n",
    "            api_data = json.loads(content.content)\n",
    "            if api_data['response']['status'] == \"error\":\n",
    "                error_msg.append(api_data['response']['message'])\n",
    "                error_counter += 1\n",
    "            else:\n",
    "                for item in api_data['response']['results']:\n",
    "                    cache_list.append(item)\n",
    "                    results_list.append(item)\n",
    "        \n",
    "                # caching results for local use\n",
    "                if cache_on:\n",
    "                    cache_save(folder_url, current_page, cache_list)\n",
    "                current_page += 1\n",
    "                error_counter = 0\n",
    "                error_msg = []\n",
    "        else:\n",
    "            error_msg.append(\"API has errored three times in a row, giving up\")\n",
    "            break\n",
    "    return results_list, error_msg\n",
    "\n",
    "# Clean up dataframe to be more visually appealing, and easier to use\n",
    "def df_creation(dataframe_name):\n",
    "    dataframe_name = dataframe_name.rename(columns = {'id':'ID', 'type':'Type', 'sectionId':'SectionID', 'sectionName':'Section Name', 'webPublicationDate':'Web Publication Date', 'webTitle':'Web Title', 'webUrl':'URL', 'apiUrl':'API URL', 'isHosted':'Is Hosted', 'pillarId': 'Pillar ID', 'pillarName':'Pillar Name'}).copy()\n",
    "    # clean the data to be more user friendly\n",
    "    if \"Web Publication Date\" in dataframe_name.columns:\n",
    "        dataframe_name[\"Web Publication Date\"] = dataframe_name[\"Web Publication Date\"].apply(lambda x: x.replace(\"T\", \" \").replace(\"Z\", \"\"))\n",
    "        if dataframe_name[\"Web Publication Date\"].dtype == object:\n",
    "            dataframe_name[\"Web Publication Date\"] = pd.to_datetime(dataframe_name[\"Web Publication Date\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        dataframe_name.sort_values(by='Web Publication Date', ascending=False, inplace=True)\n",
    "        dataframe_name[\"Month\"] = dataframe_name[\"Web Publication Date\"].dt.month\n",
    "        dataframe_name[\"Year\"] = dataframe_name[\"Web Publication Date\"].dt.year\n",
    "    if \"Pillar ID\" in dataframe_name.columns:\n",
    "        dataframe_name[\"Pillar ID\"] = dataframe_name[\"Pillar ID\"].astype(str).apply(lambda x: x.replace(\"pillar/\", \"\"))\n",
    "    \n",
    "    return dataframe_name\n",
    "\n",
    "def duplicate_check(original_df):\n",
    "    master_list = []\n",
    "    result_list = []\n",
    "    for index, row in original_df.iterrows():\n",
    "        dynamic_map = {}\n",
    "        dynamic_map[\"ID\"] = row[\"ID\"]\n",
    "        dynamic_map[\"Type\"] = row[\"Type\"]\n",
    "        dynamic_map[\"SectionID\"] = row[\"SectionID\"]\n",
    "        dynamic_map[\"Section Name\"] = row[\"Section Name\"]\n",
    "        dynamic_map[\"Web Publication Date\"] = row[\"Web Publication Date\"]\n",
    "        dynamic_map[\"Web Title\"] = row[\"Web Title\"]\n",
    "        dynamic_map[\"URL\"] = row[\"URL\"]\n",
    "        dynamic_map[\"API URL\"] = row[\"API URL\"]\n",
    "        dynamic_map[\"Is Hosted\"] = row[\"Is Hosted\"]\n",
    "        dynamic_map[\"Pillar ID\"] = row[\"Pillar ID\"]\n",
    "        dynamic_map[\"Pillar Name\"] = row[\"Pillar Name\"]\n",
    "        dynamic_map[\"Month\"] = row[\"Month\"]\n",
    "        dynamic_map[\"Year\"] = row[\"Year\"]\n",
    "        result_list.append(dynamic_map)\n",
    "\n",
    "    for item in range(len(result_list)):\n",
    "        if result_list[item] not in master_list:\n",
    "            master_list.append(result_list[item])  \n",
    "\n",
    "    new_df = pd.DataFrame(master_list)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions for HTML, and cleaning the constructed DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cleaning(df):\n",
    "    if df[\"Date\"].dtype == object:\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df.sort_values(by='Date', ascending=False, inplace=True)\n",
    "    \n",
    "    if \"Month\" not in df.columns:\n",
    "        df[\"Month\"] = df[\"Date\"].dt.month\n",
    "    if \"Year\" not in df.columns:\n",
    "        df[\"Year\"] = df[\"Date\"].dt.year\n",
    "    return df\n",
    "\n",
    "# Get HTML function\n",
    "def get_HTML(url):\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    return html\n",
    "\n",
    "# Beautiful soup function for subtitle\n",
    "def extract_subTitle(HTML):\n",
    "    soup = BeautifulSoup(HTML, \"html.parser\") # the html input and the parser name\n",
    "    article = soup.find(\"main\") # the tag that contains the article\n",
    "    div_element = article.find(\"div\", attrs={\"data-gu-name\": \"standfirst\"}) # the tag that can be found using an attribute\n",
    "    target_element = div_element.find(\"p\")\n",
    "    if target_element:\n",
    "        return target_element.text\n",
    "    else:\n",
    "        return '-'\n",
    "\n",
    "# Beautiful soup function for live articles\n",
    "def parse_article(article, temp_result):\n",
    "    fig_element = article.find(\"figure\")\n",
    "    if fig_element:\n",
    "        temp_result = ''\n",
    "    else:\n",
    "        for child in article.children:   \n",
    "            if child.name == 'p':\n",
    "                temp_result += child.text + '\\n'\n",
    "            if child.name == 'ul':\n",
    "                for li in child.findAll('li'):\n",
    "                    if li.find('ul'):\n",
    "                        break\n",
    "                    temp_result += li.text + '\\n'\n",
    "        temp_result += '\\n'\n",
    "    return temp_result\n",
    "\n",
    "# Beautiful soup function for body\n",
    "def extract_body(HTML):\n",
    "    result = \"\"\n",
    "    soup = BeautifulSoup(HTML, \"html.parser\") # the html input and the parser name\n",
    "\n",
    "    news = soup.find(\"main\", attrs={\"data-layout\": \"LiveLayout\"})\n",
    "    if news:\n",
    "        div_element = news.find(\"div\", attrs={\"id\": \"liveblog-body\"}) # the tag that can be found using an attribute\n",
    "        div_art_element = div_element.findAll(\"article\")\n",
    "        for item in div_art_element:\n",
    "            temp_result = ''\n",
    "            temp_result = parse_article(item, temp_result)\n",
    "            result += temp_result\n",
    "    else:\n",
    "        news = soup.find(\"main\") # the tag that contains the article\n",
    "        div_element = news.find(\"div\", attrs={\"id\": \"maincontent\"}) # the tag that can be found using an attribute\n",
    "        div_div_element = div_element.find(\"div\")\n",
    "        target_elements = div_element.findAll(\"p\")\n",
    "        for te in target_elements:\n",
    "            result += te.text + '\\n'*2\n",
    "            \n",
    "    return result\n",
    "\n",
    "def scraping_df(df):\n",
    "    if not os.path.exists('web-scraped-data.csv'):\n",
    "        results_data_list = []\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            dynamic_map = {}\n",
    "            dynamic_map[\"Date\"] = row[\"Web Publication Date\"]\n",
    "            dynamic_map[\"Section\"] = row[\"Section Name\"]\n",
    "            dynamic_map[\"Title\"] = row[\"Web Title\"]\n",
    "            dynamic_map[\"Subtitle\"] = extract_subTitle(get_HTML(row[\"URL\"]))\n",
    "            dynamic_map[\"Body\"] = extract_body(get_HTML(row[\"URL\"]))\n",
    "\n",
    "            results_data_list.append(dynamic_map)\n",
    "            \n",
    "        scraped_data_df = df_cleaning(pd.DataFrame(results_data_list))\n",
    "        scraped_data_df.to_csv('web-scraped-data.csv')\n",
    "        \n",
    "    else:\n",
    "        scraped_data_df = pd.read_csv('web-scraped-data.csv')\n",
    "        del scraped_data_df[\"Unnamed: 0\"]\n",
    "        scraped_data_df = scraped_data_df.replace(np.nan, '', regex=True)\n",
    "    \n",
    "    return scraped_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code utilising the created functions to acquire the relevant data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pulling results from TheGuardian api from 2017 onwards under the search condition of \"Aged care facility\" (takes up to 30 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting important variables\n",
    "aged_care_results = []\n",
    "aged_care_api_url_start = \"https://content.guardianapis.com/search?from-date=2017-01-01&to-date=2022-10-05&order-by=newest&page=\"\n",
    "aged_care_api_url_end = \"&page-size=50&q=%22Aged%20care%20facility%22&api-key=dd3e21c9-be37-4bdb-b311-2fd86c0fd153\"\n",
    "\n",
    "# getting the total page count\n",
    "aged_care_page_count = page_count(aged_care_api_url_start, aged_care_api_url_end)\n",
    "# making the cache folder directory\n",
    "if cache_on:\n",
    "    if os.path.exists(\"./cache/Aged-Care-Facility/\") is False:\n",
    "        os.makedirs(\"./cache/Aged-Care-Facility/\")\n",
    "\n",
    "# printing first result of data if no errors, else printing the error (formatted)\n",
    "if type(aged_care_page_count) == int:\n",
    "    aged_care_results, error_msg = api_scraping(aged_care_page_count, aged_care_api_url_start, aged_care_api_url_end, \"./cache/Aged-Care-Facility/\")\n",
    "    print(f\"{error_msg[3]}\\n\\nThese were the error messages:\\n1: {error_msg[0]}\\n2: {error_msg[1]}\\n3: {error_msg[2]}\\n\\nMake sure the URL is correct, then try again\") if len(error_msg) > 3 else print(aged_care_results[0])\n",
    "else:\n",
    "    print(aged_care_page_count)\n",
    "\n",
    "\n",
    "\n",
    "# 'https://content.guardianapis.com/search?from-date=2017-01-01&to-date=2022-10-05&order-by=newest&page=1&page-size=50&q=%22Aged%20care%20facility%22&api-key=dd3e21c9-be37-4bdb-b311-2fd86c0fd153'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading cache\n",
    "if cache_on:\n",
    "    aged_care_results = cache_load(\"./cache/Aged-Care-Facility/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_df = df_creation(pd.DataFrame(aged_care_results))\n",
    "ac_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pulling results from TheGuardian api from 2017 onwards under the search condition of \"residential aged care\" (takes up to 30 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting important variables\n",
    "residential_care_results = []\n",
    "residential_care_api_url_start = \"https://content.guardianapis.com/search?from-date=2017-01-01&to-date=2022-10-05&order-by=newest&page=\"\n",
    "residential_care_api_url_end = \"&page-size=50&q=%22Residential%20Aged%20Care%22&api-key=dd3e21c9-be37-4bdb-b311-2fd86c0fd153\"\n",
    "\n",
    "# getting the total page count\n",
    "residential_care_page_count = page_count(residential_care_api_url_start, residential_care_api_url_end)\n",
    "\n",
    "# making the cache folder directory\n",
    "if cache_on:\n",
    "    if os.path.exists(\"./cache/Aged-Care-Facility/\") is False:\n",
    "        os.makedirs(\"./cache/Residential-Aged-Care/\")\n",
    "\n",
    "# printing first result of data if no errors, else printing the error (formatted)\n",
    "if type(residential_care_page_count) == int:\n",
    "    residential_care_results, error_msg = api_scraping(residential_care_page_count, residential_care_api_url_start, residential_care_api_url_end, \"./cache/Residential-Aged-Care/\")\n",
    "    print(f\"{error_msg[3]}\\n\\nThese were the error messages:\\n1: {error_msg[0]}\\n2: {error_msg[1]}\\n3: {error_msg[2]}\\n\\nMake sure the URL is correct, then try again\") if len(error_msg) > 3 else print(residential_care_results[0])\n",
    "else:\n",
    "    print(residential_care_page_count)\n",
    "\n",
    "\n",
    "# 'https://content.guardianapis.com/search?from-date=2017-01-01&to-date=2022-10-05&order-by=newest&page=1&page-size=50&q=%22Residential%20Aged%20Care%22&api-key=dd3e21c9-be37-4bdb-b311-2fd86c0fd153'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading cache\n",
    "if cache_on:\n",
    "    residential_care_results = cache_load(\"./cache/Residential-Aged-Care/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_df = df_creation(pd.DataFrame(residential_care_results))\n",
    "rc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the two dataframes (as they are of the same overall topic), and removing any duplicate entries, as this could create misinformation in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two dataframes together, removing duplicate entires\n",
    "final_api_data = duplicate_check(pd.concat([ac_df, rc_df]))\n",
    "final_api_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using web scraping to retrieve certain aspects of the acquired theguardian articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scrape_df = scraping_df(final_api_data)\n",
    "final_scrape_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling the data from the provided external anonymous survey csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df = pd.read_csv('for-release-community-attitudes-survey.csv', low_memory=False)\n",
    "survey_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal Data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create functions to complete repetitive code (in this case, iterating over CSV's, cleaning up some values) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterating(df):\n",
    "    service_size_map = {1: \"1-20\", 2: \"21-40\", 3: \"41-60\", 4: \"61-80\", 5: \"81-100\", 6: \"101+\"}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if \"Service_size\" in df.keys():\n",
    "            df.loc[df[\"Service_size\"] == row[\"Service_size\"], \"Service_size\"] = re.sub(r'[^\\w\\d\\-\\=\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\_\\+\\.]', \"-\", row[\"Service_size\"])\n",
    "        else:\n",
    "            df.loc[df[\"SERVICE_SIZE\"] == row[\"SERVICE_SIZE\"], \"SERVICE_SIZE\"] = service_size_map[row[\"SERVICE_SIZE\"]]\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code utilising the created functions to acquire the relevant data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "GEN_2021_data_df = data_iterating(pd.read_csv('ServicesPlaces_2020to2021_GENdata.csv'))\n",
    "GEN_2021_data_df.columns = GEN_2021_data_df.columns.to_series().apply(lambda x: x.strip())\n",
    "GEN_2021_data_df['Operational_places'] = pd.to_numeric(GEN_2021_data_df['Operational_places'], errors='coerce')\n",
    "GEN_2021_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_2020_data_df = data_iterating(pd.read_csv('ServicesPlaces_2019to2020_GENdata.csv', encoding = 'cp1252'))\n",
    "GEN_2020_data_df.columns = GEN_2020_data_df.columns.to_series().apply(lambda x: x.strip())\n",
    "GEN_2020_data_df['Operational_places'] = pd.to_numeric(GEN_2020_data_df['Operational_places'], errors='coerce')\n",
    "GEN_2020_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_2019_data_df = data_iterating(pd.read_csv('Services-and-places-in-aged-care-30-June-2019.csv', encoding = 'cp1252'))\n",
    "GEN_2019_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create functions to complete repetitive code (in this case, searching through the DF's for keywords, and counting occurrence frequencies in dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for keyword searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searches the inputted original list of data scraped from the API for the inputted keywords, then creates a new dataframe\n",
    "def keyword_search(new_df, keywords, check):\n",
    "    results_list = []\n",
    "    master_list = []\n",
    "\n",
    "    for index, row in new_df.iterrows():\n",
    "        # defining variables for later use\n",
    "        null_count = 0\n",
    "        keyword_map = {}\n",
    "        item_Date = row[\"Date\"]\n",
    "        item_Title = row[\"Title\"]\n",
    "        item_Subtitle = row[\"Subtitle\"]\n",
    "        item_Body = row[\"Body\"]\n",
    "        item_Month = row[\"Month\"]\n",
    "        item_Year = row[\"Year\"]\n",
    "\n",
    "        # searching for the keywords inputted\n",
    "       \n",
    "        for keyword in keywords:\n",
    "            \n",
    "            keyword_map[keyword] = item_Body.lower().count(keyword.lower())\n",
    "            if keyword_map[keyword] == 0:\n",
    "                null_count += 1\n",
    "        dynamic_object = {}\n",
    "\n",
    "        # setting column variables in dynamic_object dict based on found keywords\n",
    "        dynamic_object[\"Date\"] = item_Date\n",
    "        dynamic_object[\"Title\"] = item_Title\n",
    "        dynamic_object[\"Subtitle\"] = item_Subtitle\n",
    "        dynamic_object[\"Body\"] = item_Body\n",
    "        dynamic_object[\"Month\"] = item_Month\n",
    "        dynamic_object[\"Year\"] = item_Year\n",
    "\n",
    "        if check:\n",
    "            for keyword in keywords:\n",
    "                dynamic_object[keyword] = keyword_map[keyword]\n",
    "        # appending found articles to list\n",
    "        if null_count < len(keywords):\n",
    "            results_list.append(dynamic_object)\n",
    "\n",
    "    # removing duplicate entries from list (function can be called using multiple dataframes, and will work dynamically)\n",
    "    for item in range(len(results_list)):\n",
    "        if results_list[item] not in master_list:\n",
    "            master_list.append(results_list[item])\n",
    "            \n",
    "    # creating dataframe with found results\n",
    "    master_df = pd.DataFrame(master_list)\n",
    "    master_df.sort_values(by='Date', ascending=False, inplace=True)\n",
    "\n",
    "    return master_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for counting the occurrence frequency of certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create df containing the frequency of unique values in a given column in a given dataframe\n",
    "def count_generator(df, col):\n",
    "    list = []\n",
    "    number = int(df[col].min())\n",
    "    iterate_count = int(df[col].max()) - int(df[col].min()) + 1\n",
    "\n",
    "    # iterate in the amount of the number of unique values\n",
    "    for item in range(iterate_count):\n",
    "        map = {}\n",
    "        item_Month = number\n",
    "\n",
    "        if number in df[col].values:\n",
    "            item_Count = df[col].value_counts()[number]\n",
    "        else:\n",
    "            item_Count = 0\n",
    "\n",
    "        # append values to object, then to list\n",
    "        map[col] = item_Month\n",
    "        map[\"Count\"] = item_Count\n",
    "        list.append(map)\n",
    "        number +=1\n",
    "    new_df = pd.DataFrame(list)\n",
    "    return new_df\n",
    "\n",
    "def multi_column_counter(df):\n",
    "    list = []\n",
    "    number = 1\n",
    "    \n",
    "    for item in range(12):\n",
    "        map = {}\n",
    "        item_Month = number\n",
    "        \n",
    "        if number in df[\"Month\"].values:\n",
    "            df2 = df[(df[\"Month\"] == number)]\n",
    "            item_death = df2['death'].sum()\n",
    "            item_covid = df2['covid'].sum()\n",
    "            item_corona = df2['corona'].sum()\n",
    "            item_increase = df2['increase'].sum()\n",
    "            item_staff = df2['staff'].sum()\n",
    "            item_laws = df2['laws'].sum()\n",
    "            item_legislat = df2['legislat'].sum()\n",
    "        else:\n",
    "            item_death = 0\n",
    "            item_covid = 0\n",
    "            item_corona = 0\n",
    "            item_increase = 0\n",
    "            item_staff = 0\n",
    "            item_laws = 0\n",
    "            item_legislat = 0\n",
    "\n",
    "        # append values to object, then to list\n",
    "        map[\"Month\"] = number\n",
    "        map[\"death\"] = item_death\n",
    "        map[\"covid\"] = item_covid\n",
    "        map[\"corona\"] = item_corona\n",
    "        map[\"increase\"] = item_increase\n",
    "        map[\"staff\"] = item_staff\n",
    "        map[\"laws\"] = item_laws\n",
    "        map[\"legislat\"] = item_legislat\n",
    "        list.append(map)\n",
    "        number +=1\n",
    "    return pd.DataFrame(list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for analysing the survey, creating a list of output dataframes for analysis purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def survey_analysis(df, questions, questions_answers, gender):\n",
    "    df_list = []\n",
    "    age_map = {1: \"Under 18\", 2: \"18-24\", 3: \"25-34\", 4: \"35-44\", 5: \"45-54\", 6: \"55-64\", 7: \"65-69\", 8: \"70-79\", 9: \"80-89\", 10: \"90 or older\", 99: \"Prefer not to say\"}\n",
    "    for question in questions:\n",
    "        index = questions.index(question)        \n",
    "        result_list = []\n",
    "        for answer in list(range(questions_answers[index][0], questions_answers[index][1] + 1)):\n",
    "            dynamic_map = {} \n",
    "            dynamic_map[\"Answers\"] = answer\n",
    "            for k, v in age_map.items():\n",
    "                dynamic_map[v] = len(df.loc[(df[question] == answer) & (df[\"Age Bracket\"] == k) & (df[\"HQGender\"] == gender)])\n",
    "            result_list.append(dynamic_map)\n",
    "        df_list.append(pd.DataFrame(result_list))\n",
    "        \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code utilising the created functions to analyse the acquired data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking scraped results for relevant keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df1 = keyword_search(final_scrape_df, [\"death\", \"covid\", \"corona\", \"increase\", \"staff\", \"laws\", \"legislat\"], True)\n",
    "\n",
    "keywords_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_df2 = keyword_search(final_scrape_df, [\"death\", \"covid\", \"corona\", \"increase\", \"staff\", \"laws\", \"legisla\"], False)\n",
    "\n",
    "keywords_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating lists of new DFs only containing relevant information for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_keywords_list = []\n",
    "year_keywords_count_list = []\n",
    "for i in range(int(final_scrape_df[\"Year\"].min()), int(final_scrape_df[\"Year\"].max())+1):\n",
    "    keywords_df = keywords_df1.loc[keywords_df1['Year'] == i].sort_values(by=\"Month\", ascending=True)\n",
    "    year_keywords_list.append(keywords_df)\n",
    "    year_keywords_count_list.append(multi_column_counter(keywords_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df_list = []\n",
    "year_count_list = []\n",
    "for i in range(int(final_scrape_df[\"Year\"].min()), int(final_scrape_df[\"Year\"].max())+1):\n",
    "    year_df = keywords_df1.loc[keywords_df1['Year'] == i].sort_values(by=\"Month\", ascending=True)\n",
    "    year_df_list.append(keywords_df)\n",
    "    year_count_list.append(count_generator(year_df, \"Month\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of data from survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = [\"Q2_I\", \"Q3\", \"Q18_C\", \"Q18_D\", \"Q20_B\", \"Q26_C\", \"Q27\", \"Q32A_A\", \"Q32A_B\", \"Q32A_C\", \"Q32A_D\", \"Q32A_E\", \"Q32A_F\", \"Q32A_G\", \"Q32A_H\", \"Q32A_I\", \"Q32A_J\", \"Q32b_A\", \"Q32b_B\", \"Q32b_C\", \"Q32b_D\", \"Q32b_E\", \"Q32b_F\", \"Q32b_G\", \"Q32b_H\", \"Q32b_I\", \"Q32b_J\", \"Q36\"]\n",
    "questions_answers_list = [[1, 3], [1, 5], [1, 3], [1, 3], [1, 3], [1, 3], [1, 13], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 3], [1, 99]] \n",
    "survey_male_analysis_df_list = survey_analysis(survey_df, questions_list, questions_answers_list, 1)\n",
    "survey_female_analysis_df_list = survey_analysis(survey_df, questions_list, questions_answers_list, 2)\n",
    "\n",
    "survey_analysis_df_list = [survey_male_analysis_df_list, survey_female_analysis_df_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After further analysing the survey, what were the responses for Q36?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 99]\n",
    "for age in age_list:\n",
    "    print(f'age response number: {age}')\n",
    "    print(survey_df[\"Q36\"].loc[(survey_df[\"HQGender\"] == 1) & (survey_df[\"Age Bracket\"] == 2)].value_counts())\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that people only responded either: 'they don't know' (99), or 'its not funded at all' (1). Therefore, we can alter the relevant dataframes to make visualisation easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in survey_analysis_df_list[0][-1].iterrows():\n",
    "    row_sum = int(survey_analysis_df_list[0][-1].loc[(survey_analysis_df_list[0][-1][\"Answers\"] == row[\"Answers\"])].sum(axis=1) - row[\"Answers\"])\n",
    "    if row_sum == 0:\n",
    "        survey_analysis_df_list[0][-1].drop(index, inplace=True)\n",
    "        \n",
    "survey_analysis_df_list[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in survey_analysis_df_list[1][-1].iterrows():\n",
    "    row_sum = int(survey_analysis_df_list[1][-1].loc[(survey_analysis_df_list[1][-1][\"Answers\"] == row[\"Answers\"])].sum(axis=1) - row[\"Answers\"])\n",
    "    if row_sum == 0:\n",
    "        survey_analysis_df_list[1][-1].drop(index, inplace=True)\n",
    "        \n",
    "survey_analysis_df_list[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create functions to complete repetitive code (in this case, finding frequencies of results under certain conditions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_iterator(df, col, col1, x, service_size_list):\n",
    "    dynamic_map = {}          \n",
    "    dynamic_map[col1] = x \n",
    "    for value in service_size_list:\n",
    "        try:\n",
    "            item_count = df[col].value_counts()[value]\n",
    "            dynamic_map[value] = df[col].value_counts()[value]\n",
    "        except:\n",
    "            dynamic_map[value] = 0\n",
    "    return dynamic_map\n",
    "\n",
    "def df_frequency_counter(df, col1, col_list):\n",
    "    service_size_list = [\"1-20\", \"21-40\", \"41-60\",\"61-80\", \"81-100\", \"101+\"]\n",
    "    master_list = []\n",
    "    for col in col_list:\n",
    "        results_list = []\n",
    "        for x in df[col1].unique():\n",
    "            df2 = df[(df[col1] == x)]\n",
    "\n",
    "            if df[col].dtype == object:             \n",
    "                if col == 'SERVICE_SIZE' or col == 'Service_size':\n",
    "                    results_list.append(col_iterator(df2, col, col1, x, service_size_list))\n",
    "\n",
    "                else:\n",
    "                    results_list.append(col_iterator(df2, col, col1, x, df[col].unique())) \n",
    "                  \n",
    "            else:\n",
    "                dynamic_map = {}\n",
    "                dynamic_map[col1] = x\n",
    "                dynamic_map[col] = df2[col].sum()\n",
    "\n",
    "                results_list.append(dynamic_map)\n",
    "\n",
    "        master_list.append(pd.DataFrame(results_list))\n",
    "    return master_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code utilising the created functions to analyse the data throughly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_2019_df_list = []\n",
    "gen_2019_df_list.append(df_frequency_counter(GEN_2019_data_df, \"STATE\", [\"REMOTENESS\", \"PROGRAM_TYPE\", \"ORGANISATION_TYPE\", \"SERVICE_SIZE\", \"OPERATIONAL_PLACES\"]))\n",
    "\n",
    "gen_2020_df_list = []\n",
    "gen_2020_df_list.append(df_frequency_counter(GEN_2020_data_df, \"State\", [\"Remoteness\", \"Program_type\", \"Organisation_type\", \"Service_size\", \"Operational_places\"]))\n",
    "\n",
    "gen_2021_df_list = []\n",
    "gen_2021_df_list.append(df_frequency_counter(GEN_2021_data_df, \"State\", [\"REMOTENESS\", \"Program_type\", \"Organisation_type\", \"Service_size\", \"Operational_places\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Visualisations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create functions to complete repetitive code (in this case, setting up the figures wherever possible. Note: some figures were too complex, and weren't functionised) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_instantiation(fig, fig_para_map, plot_title_map):   \n",
    "\n",
    "    if len(fig_para_map) > 0:\n",
    "        fig.suptitle(plot_title_map[\"name\"], fontweight=\"bold\", size=plot_title_map[\"size\"], y=fig_para_map[\"y\"])\n",
    "        fig.subplots_adjust(left=fig_para_map[\"left\"], bottom=fig_para_map[\"bottom\"], right=fig_para_map[\"right\"], top=fig_para_map[\"top\"], wspace=fig_para_map[\"wspace\"], hspace=fig_para_map[\"hspace\"])\n",
    "    \n",
    "    else:\n",
    "        fig.suptitle(plot_title_map[\"name\"], fontweight=\"bold\", size=plot_title_map[\"size\"]) \n",
    "\n",
    "    return fig\n",
    " \n",
    "def fig_subplotting_one(year, fig, df, fig_list, fig_parameters, legend_map):\n",
    "    for count, df in enumerate(df):\n",
    "        fig_list[count].set_title(f\"Frequency of Article Publication by Month in {year}\", fontweight=\"bold\", size=13) \n",
    "        df.plot('Month', fig_parameters[\"y\"], ax=fig_list[count], xlabel=\"Month\", ylabel=\"Frequency\", kind=fig_parameters[\"kind\"], figsize=(fig_parameters[\"figsize\"][0],fig_parameters[\"figsize\"][1])) \n",
    "        \n",
    "        if len(legend_map) > 1:\n",
    "            fig_list[count].legend(bbox_to_anchor=(legend_map[\"bbox_to_anchor\"][0],legend_map[\"bbox_to_anchor\"][1]), loc=legend_map[\"loc\"], borderaxespad=legend_map[\"borderaxespad\"])\n",
    "        else:\n",
    "            fig_list[count].legend(loc=legend_map[\"loc\"])\n",
    "        year += 1\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code utilising the created functions to visualise the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the publication frequency of relevant articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2, ax3, ax4, ax5) = plt.subplots(nrows=6,  ncols=1)\n",
    "vis_instantiation(fig, {}, {\"name\": \"Frequency of Article Publications relating\\nto aged care services\", \"size\": 15})\n",
    "\n",
    "year = final_scrape_df[\"Year\"].min()\n",
    "fig_subplotting_one(year, fig, year_count_list, [ax0, ax1, ax2, ax3, ax4, ax5], {\"y\": ['Count'], \"figsize\": [5,10], \"kind\": \"line\"}, {\"loc\": 'upper left'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the keyword occurrence frequency of published articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2, ax3, ax4, ax5) = plt.subplots(nrows=6,  ncols=1)\n",
    "vis_instantiation(fig, {}, {\"name\": \"Frequency of Article Publications per year with certain keywords\", \"size\": 15})\n",
    "\n",
    "year = final_scrape_df[\"Year\"].min()\n",
    "fig_subplotting_one(year, fig, year_keywords_count_list, [ax0, ax1, ax2, ax3, ax4, ax5], {\"y\": [\"death\", \"covid\", \"corona\", \"increase\", \"staff\", \"laws\", \"legislat\"], \"figsize\": [10,15], \"kind\": \"bar\"}, {\"bbox_to_anchor\": [1.05, 1], \"loc\": 'upper left', \"borderaxespad\": 0.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse the relevant questions in the survey results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = [\"Q2_I\", \"Q3\", \"Q18_C\", \"Q18_D\", \"Q20_B\", \"Q26_C\", \"Q27\", \"Q32A_A\", \"Q32A_B\", \"Q32A_C\", \"Q32A_D\", \"Q32A_E\", \"Q32A_F\", \"Q32A_G\", \n",
    "                \"Q32A_H\", \"Q32A_I\", \"Q32A_J\", \"Q32b_A\", \"Q32b_B\", \"Q32b_C\", \"Q32b_D\", \"Q32b_E\", \"Q32b_F\", \"Q32b_G\", \"Q32b_H\", \"Q32b_I\", \"Q32b_J\", \"Q36\"]\n",
    "\n",
    "fig, ((ax0, ax1), (ax2, ax3), (ax4, ax5), (ax6, ax7), (ax8, ax9), (ax10, ax11), (ax12, ax13), (ax14, ax15), (ax16, ax17), (ax18, ax19), \n",
    "    (ax20, ax21), (ax22, ax23), (ax24, ax25), (ax26, ax27), (ax28, ax29), (ax30, ax31), (ax32, ax33), (ax34, ax35), (ax36, ax37), (ax38, ax39), \n",
    "    (ax40, ax41), (ax42, ax43), (ax44, ax45), (ax46, ax47), (ax48, ax49), (ax50, ax51)) = plt.subplots(nrows=26, ncols=2)\n",
    "\n",
    "vis_instantiation(fig, {\"left\": 0.125, \"bottom\": 0.1, \"right\": 0.9, \"top\": 18, \"wspace\": None, \"hspace\": None, \"y\": 18.15}, {\"name\": \"Survey Responses by Gender\", \"size\": 20})\n",
    "\n",
    "fig_list = [ax0, ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12, ax13, ax14, ax15, ax16, ax17, ax18, ax19, ax20, ax21, \n",
    "    ax22, ax23, ax24, ax25, ax26, ax27, ax28, ax29, ax30, ax31, ax32, ax33, ax34, ax35, ax36, ax37, ax38, ax39, ax40, ax41, ax42, ax43, ax44, \n",
    "    ax45, ax46, ax47, ax48, ax49, ax50, ax51]\n",
    "\n",
    "fig_count = 0\n",
    "if len(survey_analysis_df_list) > 0:\n",
    "    for index in range(len(survey_analysis_df_list[0])):\n",
    "        if len(survey_analysis_df_list[0][index]) > 3:\n",
    "            continue\n",
    "        \n",
    "        fig_list[fig_count].set_title(f\"Male responses to survey {questions_list[index]}\", fontweight=\"bold\", size=12)\n",
    "        survey_analysis_df_list[0][index].plot(\"Answers\", [\"Under 18\", \"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65-69\", \"70-79\", \"80-89\", \"90 or older\", \"Prefer not to say\"], \n",
    "                                                ax=fig_list[fig_count], kind=\"bar\", xlabel=\"Answer\", ylabel=\"Frequency\", figsize=(15,5))\n",
    "        fig_list[fig_count].legend().remove()\n",
    "        fig_count += 1\n",
    "\n",
    "        fig_list[fig_count].set_title(f\"Female responses to survey {questions_list[index]}\", fontweight=\"bold\", size=12)\n",
    "        survey_analysis_df_list[1][index].plot(\"Answers\", [\"Under 18\", \"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65-69\", \"70-79\", \"80-89\", \"90 or older\", \"Prefer not to say\"], \n",
    "                                                ax=fig_list[fig_count], kind=\"bar\", xlabel=\"Answer\", ylabel=\"Frequency\", figsize=(15,5))\n",
    "        fig_list[fig_count].legend(ncol=1, labelspacing=0., bbox_to_anchor=(1.4, .7), borderaxespad=0.)\n",
    "        fig_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax0, ax1), (ax2, ax3), (ax4, ax5), (ax6, ax7), (ax8, ax9), (ax10, ax11), (ax12, ax13), (ax14, ax15), (ax16, ax17), (ax18, ax19), \n",
    "    (ax20, ax21)) = plt.subplots(nrows=11, ncols=2)\n",
    "fig.suptitle(\"Survey Responses by Gender\", fontweight=\"bold\", size=20, y=9.15)\n",
    "fig.subplots_adjust(left=0.25, bottom=0.1, right=1.3, top=9, wspace=None, hspace=None)\n",
    "\n",
    "fig_list = [ax0, ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12, ax13, ax14, ax15, ax16, ax17, ax18, ax19, ax20 , ax21]\n",
    "\n",
    "fig_count = 0\n",
    "keys_list = [n for n in survey_analysis_df_list[0][1].keys()]\n",
    "keys_list.pop(0)\n",
    "\n",
    "for key in keys_list:\n",
    "    \n",
    "    fig_list[fig_count].set_title(f\"Males ages {key} responses to survey Q3\", fontweight=\"bold\", size=10)\n",
    "    survey_analysis_df_list[0][1].plot(\"Answers\", key, ax=fig_list[fig_count], kind=\"bar\", xlabel=\"Answer\", ylabel=\"Frequency\", figsize=(7,5), color='brown')\n",
    "    fig_list[fig_count].legend().remove()\n",
    "    fig_count += 1\n",
    "\n",
    "    fig_list[fig_count].set_title(f\"Female ages {key} responses to survey Q3\", fontweight=\"bold\", size=10)\n",
    "    survey_analysis_df_list[1][1].plot(\"Answers\", key, ax=fig_list[fig_count], kind=\"bar\", xlabel=\"Answer\", ylabel=\"Frequency\", figsize=(7,5), color='brown')\n",
    "    fig_list[fig_count].legend().remove()\n",
    "    fig_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = [\"Q3\", \"Q27\", \"Q36\"]\n",
    "fig, ((ax0, ax1), (ax2, ax3), (ax4, ax5), (ax6, ax7), (ax8, ax9), (ax10, ax11), (ax12, ax13), (ax14, ax15), (ax16, ax17), (ax18, ax19), \n",
    "    (ax20, ax21)) = plt.subplots(nrows=11, ncols=2)\n",
    "fig.suptitle(\"Survey Responses by Gender\", fontweight=\"bold\", size=20, y=9.15)\n",
    "fig.subplots_adjust(left=0.25, bottom=0.1, right=1.3, top=9, wspace=None, hspace=None)\n",
    "\n",
    "fig_list = [ax0, ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12, ax13, ax14, ax15, ax16, ax17, ax18, ax19, ax20 , ax21]\n",
    "\n",
    "fig_count = 0\n",
    "keys_list = [n for n in survey_analysis_df_list[0][6].keys()]\n",
    "keys_list.pop(0)\n",
    "\n",
    "for key in keys_list:\n",
    "    \n",
    "    fig_list[fig_count].set_title(f\"Males ages {key} responses to survey Q27\", fontweight=\"bold\", size=11)\n",
    "    survey_analysis_df_list[0][6].plot(\"Answers\", key, ax=fig_list[fig_count], kind=\"bar\", xlabel=\"Answer\", ylabel=\"Frequency\", figsize=(10,5), color='forestgreen')\n",
    "    fig_list[fig_count].legend().remove()\n",
    "    fig_count += 1\n",
    "\n",
    "    fig_list[fig_count].set_title(f\"Female ages {key} responses to survey Q27\", fontweight=\"bold\", size=11)\n",
    "    survey_analysis_df_list[1][6].plot(\"Answers\", key, ax=fig_list[fig_count], kind=\"bar\", xlabel=\"Answer\", ylabel=\"Frequency\", figsize=(10,5), color='forestgreen')\n",
    "    fig_list[fig_count].legend().remove()\n",
    "    fig_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal Visualisations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create functions to complete repetitive code (in this case, visualising the data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internal_vis_instantiation(fig, fig_para_map, plot_title_map):   \n",
    "\n",
    "    if len(fig_para_map) > 0:\n",
    "        fig.suptitle(plot_title_map[\"name\"], fontweight=\"bold\", size=plot_title_map[\"size\"], y=fig_para_map[\"y\"])\n",
    "        fig.subplots_adjust(left=fig_para_map[\"left\"], bottom=fig_para_map[\"bottom\"], right=fig_para_map[\"right\"], top=fig_para_map[\"top\"], wspace=fig_para_map[\"wspace\"], hspace=fig_para_map[\"hspace\"])\n",
    "    \n",
    "    else:\n",
    "        fig.suptitle(plot_title_map[\"name\"], fontweight=\"bold\", size=plot_title_map[\"size\"]) \n",
    "\n",
    "    return fig\n",
    " \n",
    "def internal_fig_subplotting_one(fig, df, fig_list, fig_parameters, legend_map):\n",
    "    title_list = [\"remoteness\", \"program type\", \"organisation type\", \"service size\", \"operational places\"]\n",
    "\n",
    "    for count, df in enumerate(df):\n",
    "        keys_list = [n for n in df.keys()]\n",
    "        keys_list.remove(fig_parameters[\"x\"])\n",
    "\n",
    "        fig_list[count].set_title(f'Internal data \"{title_list[count]}\" column aggregation per {fig_parameters[\"xlabel\"].lower()}', fontweight=\"bold\", size=13) \n",
    "        df.plot(fig_parameters[\"x\"], keys_list, ax=fig_list[count], xlabel=fig_parameters[\"xlabel\"], ylabel=fig_parameters[\"ylabel\"], kind=fig_parameters[\"kind\"], figsize=(fig_parameters[\"figsize\"][0],fig_parameters[\"figsize\"][1])) \n",
    "        \n",
    "        if len(legend_map) > 1:\n",
    "            fig_list[count].legend(bbox_to_anchor=(legend_map[\"bbox_to_anchor\"][0],legend_map[\"bbox_to_anchor\"][1]), loc=legend_map[\"loc\"], borderaxespad=legend_map[\"borderaxespad\"])\n",
    "        else:\n",
    "            fig_list[count].legend(loc=legend_map[\"loc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code utilising the created functions to acquire the relevant data for visualisation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2, ax3, ax4) = plt.subplots(nrows=5,  ncols=1)\n",
    "internal_vis_instantiation(fig, {\"left\": 0.125, \"bottom\": 0.1, \"right\": 0.9, \"top\": 1.2, \"wspace\": None, \"hspace\": .4, \"y\": 1.25}, {\"name\": \"Aged care facility information analysis per state in 2019\", \"size\": 15})\n",
    "\n",
    "internal_fig_subplotting_one(fig, gen_2019_df_list[0], [ax0, ax1, ax2, ax3, ax4], {\"x\": \"STATE\", \"xlabel\": \"State\", \"ylabel\": \"Frequency\", \"figsize\": [10,15], \"kind\": \"bar\"}, {\"bbox_to_anchor\": [1.05, 1], \"loc\": 'upper left', \"borderaxespad\": 0.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2, ax3, ax4) = plt.subplots(nrows=5,  ncols=1)\n",
    "internal_vis_instantiation(fig, {\"left\": 0.125, \"bottom\": 0.1, \"right\": 0.9, \"top\": 1.2, \"wspace\": None, \"hspace\": .4, \"y\": 1.25}, {\"name\": \"Aged care facility information analysis per state in 2020\", \"size\": 15})\n",
    "\n",
    "internal_fig_subplotting_one(fig, gen_2020_df_list[0], [ax0, ax1, ax2, ax3, ax4], {\"x\": \"State\", \"xlabel\": \"State\", \"ylabel\": \"Frequency\", \"figsize\": [10,15], \"kind\": \"bar\"}, {\"bbox_to_anchor\": [1.05, 1], \"loc\": 'upper left', \"borderaxespad\": 0.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2, ax3, ax4) = plt.subplots(nrows=5,  ncols=1)\n",
    "internal_vis_instantiation(fig, {\"left\": 0.125, \"bottom\": 0.1, \"right\": 0.9, \"top\": 1.2, \"wspace\": None, \"hspace\": .4, \"y\": 1.25}, {\"name\": \"Aged care facility information analysis per state in 2021\", \"size\": 15})\n",
    "\n",
    "internal_fig_subplotting_one(fig, gen_2021_df_list[0], [ax0, ax1, ax2, ax3, ax4], {\"x\": \"State\", \"xlabel\": \"State\", \"ylabel\": \"Frequency\", \"figsize\": [10,15], \"kind\": \"bar\"}, {\"bbox_to_anchor\": [1.05, 1], \"loc\": 'upper left', \"borderaxespad\": 0.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The overall concern:**\n",
    "\n",
    "The overall concern the external data is looking to analyse is any opportunities or threats to our client regarding one of the following areas: <br />\n",
    "-\tthe community’s understanding of the needs of the sector  <br />\n",
    "-\tthe potential impact of government action <br />\n",
    "-\ttheir own influence sphere within the sector <br />\n",
    "\n",
    "**What data was used:**\n",
    "\n",
    "To analyse these primary areas, a variety of data was used. This data was primarily sourced from the guardian API as it is an internationally trusted and utilised news source that contains a large amount of articles on similarly numerous topics. From the guardian API, we sourced every article from 2017 onwards on one of the two following topics: <br />\n",
    "-\tAged care facilities <br />\n",
    "-\tResidential aged care <br />\n",
    "\n",
    "These topics are quite self-explanatory as our client is a not-for-profit residential aged care facility. We searched the API for these two search terms independently as this would provide a wider range of relevant articles for analysis. Additionally, we elected to utilise data from an anonymised survey of unrelated participants. This survey consisted of forty questions centred around aged care facilities and the community's understanding of the sector.\n",
    "\n",
    "\n",
    "**How the data was analysed:**\n",
    "\n",
    "The analysis performed using the data consisted of three main steps. The first step involved identifying the overall topic and retrieving this data from the guardian API. Once all the data was retrieved, it was placed into a data frame for further analysis. The frequent use of data frames achieves two main goals, being persistent data storage under variable names for easy accessibility, and a visually appealing medium for viewing the data. After the articles were acquired from the API, HTML scraping was conducted to acquire the titles, subtitles, and body text of all acquired articles. The same process was completed for the data in the survey results.\n",
    "\n",
    "The second step involved analysing the data for any immediate underlying trends and preparing it for visualisation purposes. This was completed by searching through the scraped titles, subtitles, and body text for relevant keywords, and creating a new data frame for every article containing the date of the article, the title, subtitle, and body of the article, and the total occurrence frequency of each keyword. Individualising the output results of each keyword allows for an easier time analysing each keyword specifically or analysing keyboards against each other to identify a common trend. To analyse the data from the survey, a slightly different process was performed. Firstly, questions relating to the overall business concern were identified. Using these questions, a list of data frames was created containing the results of the questions broken up do male and female responses. These lists were then concatenated into one overall list for accessibility sake. It was identified in this step that in the final relevant question (Q36), the responses given were a percentage range on the amount that aged care facilities for government funded. However, a response of one indicated that they were not government funded, and a responsive 99 indicated that the participant was unsure. It was found that every single participant both male and female only responded either one or ninety-nine. Therefore, for visualisation pragmatism, the data frame was stripped to only contain the amount of results for a response of one or 99.\n",
    "\n",
    "The last step of analysis involved visualising the data. The two types of graphs used were line graphs and bar graphs. Line graphs were strictly used to visualise the frequency of article publications relating to aged care services per year. Bar graphs were heavily utilised when analysing multiple pieces of data against each other. An example of this is the first bar graph created, where it shows for each month (per year) the occurrence frequency of keywords in published articles.\n",
    "\n",
    "**What do the visualisations tell us:** \n",
    "\n",
    "Looking at the first graph (frequency of article publications relating to aged care services), an interesting trend can be identified. Firstly, articles on this topic were relatively uncommon in 2017, 2018, and 2019 where the count peaked at around 10 articles. Interestingly in these three years, and increase can be identified from around the 7th month onwards. However due to the limited data, no concrete conclusion can be drawn. From 2020 onwards, articles on this topic became much more frequently occurring with the potential cause of this being identified in the next set of graphs. However, in both 2020 and 2021, there still remained a spike in article publication around the eight month. This could be for two reasons: \n",
    "-\tthe first reason could be the same reason behind the sudden increase from the seventh month onwards in 2017, 2018, and 2019. \n",
    "-\tthe second reason is uncovered in the next graph showcasing the keywords. \n",
    "\n",
    "Finally, the 2022 results show a decline in article publication as the progresses.\n",
    "\n",
    "In the second set of graphs, the articles published were analysed using the following keywords:\n",
    "-\tDeath\n",
    "-\tCovid\n",
    "-\tCorona\n",
    "-\tIncrease\n",
    "-\tStaff\n",
    "-\tLaws\n",
    "-\tLegislat (was specifically legistlat to cover both legislate, legislative, and legislature)\n",
    "\n",
    "Death, increase, and staff was chosen as frequent appearances of death relating to aged care services could heavily negatively impact the communities perception of the sector. Whereas an article containing the words increase or staff would not be using these words positively, therefore leading to a harmed community perception. Covid and corona are self-explanatory, and laws/legislat were chosen to potentially identify any legal or governmental impacts on aged care.\n",
    " \n",
    "Obviously as the covid-19 pandemic hit media in 2020, there were no results for either covid or corona. In the years prior to the pandemic, the front running keywords were staff and death. Every other identified keyword did not have enough results to identify a trend. The keyword staff appeared primarily between the third and fifth months, and the 9th and 11th months. The repetitive popularity in autumn and spring specifically could be due to a number of reasons:\n",
    "-\tStaffing shortages occur at these times specifically as new workers starting at the start or middle of the year would have been working for a few months, and could be leaving the sector after this amount of experience for internal reasons\n",
    "-\tHiring waves occur at these times of year of the year, therefore articles on this sector would be frequently talking about staff\n",
    "-\tRiots or protests could frequently occur at these times of the year\n",
    "\n",
    "However, due to limited information, no clear conclusion can be reached as to which reason is correct.\n",
    "\n",
    "When analysing the graphs containing the results from 2020 onwards, it is clear that articles containing the keyword covid heavily dominated. Prior to 2020, the highest frequency of any keyword was forty. However in 2020 and 2021, the lowest frequency of covid was roughly 40. Furthermore, in 2021 the staff keyword had a similar trend to covid as can be seen from the 2nd to the 7th month. Therefore it can be assumed that at the start of the pandemic (2020) mainstream media was commonly mentioning the pandemic in relation to aged care services, then as the pandemic progressed (2021) staffing shortages or problems relating to staff were commonly mentioned along with the pandemic (showing that the staffing problems were directly correlated to the pandemic), and finally as the pandemic started fizzling out (2022), it became far less commonly occurring in the media, as seen by the continual downward trend.\n",
    "\n",
    "The final three sets of graphs are all in relation to the external survey provided. Although a large number of questions when visualised, they are all relevant and each contain interesting information. The acquired information is as follows:\n",
    "\n",
    "-\t2I\n",
    "    - Vast majority of participants both male and female agree that society has an obligation to care for older people\n",
    "-\t3\n",
    "    - Participants across all genders up to the age of sixty-nine agree that the government should be paying for aged care, however in ages seventy onwards, some agree that the government should pay, whereas others agree that the older person themselves should pay\n",
    "-\t18c/d\n",
    "    - Vast majority of participants both male and female agree that showering, dressing, toilet, and medication assistance are all particularly important services provided by age care facilities\n",
    "-\t20b\n",
    "    - Vast majority of participants both male and female think that they will be healthy enough to be able to care for themselves in their 70s and 80s\n",
    "-\t26c\n",
    "    - Somewhat even split from participant responses on whether or not they know someone who receives homecare support\n",
    "-\t27\n",
    "    - Across all ages and genders, the common three responses are that the participants visits the person they know (who receives personal support) either once a week, several times a week, or several times a year. The exact preference of these responses varies between eight groups \n",
    "-\t32:\n",
    "    - If the participant has visited an aged care facility, these are the common understandings of said facilities:\n",
    "        - Food quality received is highly contested\n",
    "        - Facilities are safe\n",
    "        - Highly contested over whether there are enough activities to entertain people\n",
    "        - Somewhat contested over weather people in facilities receive the help they need on time\n",
    "        - Agreed that the accommodation is comfortable and well maintained\n",
    "        - Agreed that people in facilities are often lonely\n",
    "        - Agreed that people in facilities do not have control over their own lives\n",
    "        - Agreed that people have timely access to medical professionals and other health care\n",
    "        - Somewhat contested over whether people in facilities are respected \n",
    "        - Agreed that people are not happy in facilities\n",
    "    - If the participant has not visited an aged care facility, these are the common understandings of said facilities:\n",
    "        - Indecisive over the food quality\n",
    "        - Somewhat agree that people are safe in facilities\n",
    "        - Indecisive over whether there are enough activities to keep people entertained\n",
    "        - Somewhat agree that people receive the help they need on time\n",
    "        - Agree that the accommodation is comfortable and well maintained\n",
    "        - Agree that people in facilities are often lonely\n",
    "        - Agree that people in facilities do not have control over their lives\n",
    "        - Agreed that people have timely access to medical professionals and other health care\n",
    "        - Indecisive over whether people in facilities are respected or not\n",
    "        - Somewhat agree that people are not happy in facilities\n",
    "-\t36\n",
    "    - Most participants agree that aged care facilities on not funded by the government\n",
    "\n",
    "When analysing all the responses, noticeably clear trends can be seen. Firstly, it is evident that society understands the intrinsic value of aged care services however at the same time it is evident that participants do not wish to themselves be in said facilities (see q2i/q18/q20). Furthermore, participants agree that the government should be funding age care facilities, however the consensus is that age care facilities currently receive no funding (q3/q36). When coupling these results with the responses from q26/q27/q32, an interesting conclusion could be reached. As seen in question 32, common points of contention for facilities are the food quality, the limited amount of entertaining activities, access to required help (results from staffing issues), limited access to other members of society, and restricted control over their own lives. With the exception of access to other members of society and control over their own lives, participants seemed to agree that every point of contention can be immediately remedied with more funding. Thus, if more funding is acquired and these points are remedied, the societal perception of aged care facilities will likely heavily increase.\n",
    "\n",
    "**Opportunities:**\n",
    "-\tAs society understands the value of aged care services, this will make any further improvements more effective\n",
    "-\tProve to society that aged care facilities are far better than currently understood\n",
    "-\tCan receive government funding (publicly as well) to improve the conditions of facilities\n",
    "\n",
    "**Threats:**\n",
    "-\tSociety has a clear discriminant view of aged care facilities\n",
    "-\tThis ever-present view will limit the number of people willing to work in said facilities\n",
    "-\tPeople with a harshly negative view on facilities will be far less considerate of said facilities if they ever join one\n",
    "-\tMedia presence of aged care facilities is related to events on the scale of a global pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Internal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The overall concern:**\n",
    "\n",
    "The overall concern the internal data is looking to analyse is any strengths or weaknesses to our client that could be used to impact one of the following areas\n",
    "-\tthe community’s understanding of the needs of the sector\n",
    "-\tthe potential impact of government action\n",
    "-\ttheir own influence sphere within the sector\n",
    "\n",
    "**What data was used:**\n",
    "\n",
    "To analyse these primary areas, data obtained internally (csv containing reports of aged care facilities) was acquired and analysed. These reports contain a range of useful information, such as (for each facility):\n",
    "-\tThe state the facility is located in\n",
    "-\tThe program type\n",
    "-\tThe organization type\n",
    "-\tThe service size (number of employees)\n",
    "-\tThe operational places\n",
    "\n",
    "\n",
    "**How the data was analysed:**\n",
    "\n",
    "The analysis performed consisted of three main steps. The first step was simply importing the reports from 2019 onwards into data frames, then iterating over the data frames to make the data are more versatile and universally applicable for the analysis. An example of this is changing the operational places values into floats instead of strings.\n",
    "\n",
    "The second step involved analysing the data, and creating a list of the resulting output data frames. These data frames consisted of an analysis of the following information column\n",
    "-\tNumber of facilities of each remoteness type per state\n",
    "-\tNumber of facilities of each program type per state\n",
    "-\tNumber of facilities of each organization type per state\n",
    "-\tNumber of facilities of each service size per state\n",
    "-\tTotal number of operational places per state\n",
    "This allowed for a clear understanding of the data, and immediately identifies any common underlying trends.\n",
    "\n",
    "The final step involved visualising the data. Only one graph type was used, being bar graphs. As each analysis performed and visualisation is comparing different data points, bar graphs are very effective method of achieving this plus also keeping a high level of clarity.\n",
    "\n",
    "\n",
    "\n",
    "**What do the visualisations tell us:** \n",
    "\n",
    "When looking at the graphs depicting the remoteness of facilities across every year, a clear trend can be identified. That is, in every state (excluding NT) the vast majority of facilities are in major cities of Australia. However, in the NT, there are no facilities in a ‘major city’. Additionally, there are almost no facilities in either remote Australia or very remote Australia throughout every single state. This means that if someone is not in a major city of Australia, in a regional Australia, or in some cases auto regional Australia, they have extremely limited access to aged care services. \n",
    "\n",
    "Additionally, in 2019, nearly every single recorded facility provides solely residential care. In 2020 and 2021, nearly every facility is either a residential care or a home care facility. However, this means that if someone requires any service outside of home or residential care (for example, short term restorative care, transition care, multipurpose service, or innovative care), they have almost no options available to them.\n",
    "\n",
    "Furthermore, in most every states in 2019, there appears to be a even split between not for profit, private, or government facilities. Notably NSW and QLD are majority not for profit facilities. However, in 2020 in 2021 every state contains a vast majority of not-for-profit facilities. Therefore, it can be assumed that government and private facilities either lost their funding or for any reason ceased to exist after 2019. However interestingly, across all three years and every state there seems to be an even split in the service size values. Thus, even though majority of facilities they came not for profit after 2019, their service sizes weren’t impacted.\n",
    "\n",
    "Finally, NSW, Victoria, and QLD are consistently the top three states with the most operational places. This makes perfect sense as these three states are the three most populous throughout Australia, thus requiring the most amount of facilities.\n",
    "\n",
    "\n",
    "**Strengths:**\n",
    "-\thigh accessibility for aged care facilities in most populated states\n",
    "-\tmost facilities are not for profit, therefore potentially increasing the public view as these facilities are not profiting from in need patients\n",
    "-\thigh accessibility for facilities in major cities\n",
    "\n",
    "\n",
    "\n",
    "**Weaknesses:**\n",
    "-\tincredibly limited accessibility outside of regional Australia (or in NT/SA/Tasmania)\n",
    "-\talmost no facilities providing services other than home care or residential care\n",
    "-\tno private or government facilities means limited funding, thus lowers the quality of service provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**S and O:**\n",
    "-\tImprove services provided in major cities to impact as many people as possible to prove to society that aged care facilities are much better than is currently perceived\n",
    "-\tProvide more facilities in popular states to prove to society that aged care facilities are much better than is currently perceived\n",
    "\n",
    "**S and T:**\n",
    "-\tIncrease public knowledge that nearly every facility is not for profit to improve the current discriminant perception\n",
    "-\tIncreasing public knowledge will also increase the current media presence, thus removing the current requirement of an event such as a pandemic (for high media presence), and will spark a conversation in the media about current problems (outside of their control) and solutions for aged care facilities\n",
    "\n",
    "**W and O:**\n",
    "-\tTry to humanise aged care services to prove that the widely acknowledged problems are out of their control (with current funding)\n",
    "-\tReceiving government funding to improve the service quality, and increase awareness of improved facility quality\n",
    "-\tIncreasing accessibility of facilities outside of regional Australia or in states aside from QLD/NSW/VIC will further improve societies perception\n",
    "\n",
    "**W and T:**\n",
    "-\tTry to humanise aged care services to prove that the current perception is unfair given the funding amounts, staffing issues, etc. \n",
    "-\tIncreasing accessibility of facilities outside of regional Australia or in states aside from QLD/NSW/VIC To improve the current pessimist view of aged care facilities\n",
    "-\tIncreasing accessibility of facilities outside of regional Australia or in states aside from QLD/NSW/VIC to increase the amount of people able to and willing to work in said facilities\n",
    "\n",
    "\n",
    "**Recommendations:**\n",
    "-\tIncrease amount of facilities outside of regional Australia and in states aside from Queensland, NSW, or Vic\n",
    "    - will improve any negative societal perceptions based on accessibility problems\n",
    "-\tincrease accessibility of services aside from home care and residential care\n",
    "-\treceive government funding to improve service quality. Further:\n",
    "    - improved service quality will remedy both the current societal perception, and will result in more people willing to attend such facilities\n",
    "    - improved societal perception well increase the number of people willing to work in aged care facilities\n",
    "-\tincrease media presence\n",
    "    - spark conversations on the current problems, their causes, and solutions\n",
    "    - increase media awareness of the causes of such problems will likely which is the amount of societal criticism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the provided internal data lacks clarity on some areas:\n",
    "    - Limited information into the makeup of each service center\n",
    "    - some value names are a bit vague, could be better clarified\n",
    "- some of the external data columns are poorly explained (i.e., SEIFA_DECILE and SEIFA_SCORE)\n",
    "- limited information on our client's organisation, hard to directly relate findings to our client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## [5] Peer review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback received - reviewer 1: COOPER TOMLINSON (n10750436)\n",
    "\n",
    "- Code is very impressive, dynamic and presented well. \n",
    "    - Easy to read and commented throughout\n",
    "- Report is excessive in length, may not be able to present findings in the given time\n",
    "    - Reduce data ranges?\n",
    "    - This can be accomplished in certain places\n",
    "    - Not sure why you need to sort survey responses by gender (pretty much identical responses) \n",
    "- Check code comments, some mention the first assignment (Ukraine etc.)\n",
    "    - Code utilising the created functions to analyse the acquired data\n",
    "- I recommend you actually demonstrate analysis throughout the report rather than all in the insight section. Insight section can just wrap things up. It would probably be more cohesive. For example, with the external analysis, you complete the guardian API data scraping and then move on to processing the survey responses, and then you explain everything in detail at the end in the insight section. I think there needs to be a break between the end of the guardian API and the start of the survey responses, where you talk about what the data found from the Guardian API tells us. I get you’re trying to follow the unique QDAVDAVI cycle for the external analysis section, but my suggestions may allow the report to flow better for presentation purposes. I suggest QDAVIDAVII.\n",
    "- Frequency of article publications by month with certain keywords uses the year 2017 in all graphs? Is this meant to be 2017-2022?\n",
    "- Check capitalisation for certain headings and titles\n",
    "- Other than that it was really good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback received - reviewer 2: Louis Michael (n10631429)\n",
    "\n",
    "**External Analysis**\n",
    "- You have a very thorough dataset however a 5 year time period might be a little excessive especially considering all the recent revelations in aged-care regarding the mis-handling of the covid pandemic in the sector, staff-shortages, etc\n",
    "    - Furthermore, your keyword  finder dfs (keywords_df1 / 2) only searched more recent topics (covid, staff-shortages, isolation legislation etc.).\n",
    "- I think that there’s a mistake with some of your graph titles because the “Frequency of Article Publication by month in xxxx” graphs all say 2017.\n",
    "- I like how you separated the age groups in the survey however I feel like it is a bit redundant to separate the genders too especially considering they didn’t not show any major differences\n",
    "- Some of your graphs are empty in the “Survey Responses by Gender” section\n",
    "\n",
    "**Internal Analysis**\n",
    "- I really like how you compared the gen_data throughout the years\n",
    "- I also like how you renamed all your columns to make the visualisations more readable\n",
    "\n",
    "**Overall**\n",
    "- Your code is very well written and presented well (using a cached file is genius)\n",
    "- Your explanations / TOWS are well written\n",
    "    - I personally like how you added a section mentioning what data you used and how you analysed it\n",
    "    - However, I’m not too sure how relevant the “receive government funding” opportunity / recommendation is to this scenario considering the organisation is hiring us to figure out the best way to spend their recently received philanthropic funding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response to feedback received:\n",
    "\n",
    "- I appreciate the comments on my code clarity and presentation\n",
    "- there were a number of comments containing incorrect information, this was an accident and has been remedied\n",
    "- there was originally a bug with the code where some of the graph titles didn’t display the correct year, this has been fixed\n",
    "- There was a comment regarding a potentially excessive data set period in combination with the keywords analysed. this was done because the keywords created are relevant to today's standards and potential issues that could affect the client, analysing these in previous years helped identify trends and potential causes for concern\n",
    "- in the graphs containing the survey responses, separating responses by gender was done because originally, I suspected that there would be major differences in the responses to each question based on the gender. However, after analysing the visualisations, this is not the case. However, it was still included as there are slight differences\n",
    "- The report layout has been modified from the original layout to reflect a more ‘report’ influenced layout as opposed to a QDAVI influenced layout. this increased the readability, however, can still be a little hard to follow in some areas\n",
    "- Although the client hired us to figure out the best way to spend their recently received philanthropic funding, identifying an opportunity or recommendation to receive some government funding allows our client an idea as to a potential action further improving their current situation <br />\n",
    "\n",
    "Overall:\n",
    "- Overall, the feedback received was high quality, addressing areas of improvement and identifying what was done well. applying this feedback allows me to improve my current report, and provide a higher quality analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback given to reviewer 1:\n",
    "\n",
    "**External:**\n",
    "-\tThe question should be a bit more refined, right now it's hard to understand the points of the external analysis (for example, why are you looking at the opportunities and threats)\n",
    "-\tI like how you renamed the data frame columns to increase readability \n",
    "-\tI like the ‘word frequency’ data frame, provides a great visualisation for key areas relevant to the client\n",
    "-\tI would look at changing your survey results file path (when calling it in your code), it could cause some issues for the marker as they may not have that exact file path\n",
    "-\tI like the way you replaced the data in the survey data frame to increase readability for your graph. Very clean way to do it\n",
    "-\tI would like to see the bar graphs of the survey responses, right now there's no way to visualise anything\n",
    "-\tmissing insights for external data/analysis\n",
    "-\tmarkdown could be better utilised to demonstrate your thinking\n",
    "\n",
    "**Internal:**\n",
    "-\tThe question should be a bit more refined, right now it's hard to understand the points of the internal analysis (for example, why are you looking at the strengths and weaknesses)\n",
    "-\tI would look at changing the file path for your report CSV file, same as previous\n",
    "-\tI like how you narrowed the scope to Queensland, provides a more personal analysis\n",
    "-\tI like how you renamed the data frame columns to increase readability \n",
    "-\tI don't quite follow where you got the information that “‘real care’ possesses 41-60 locations in the metropolitan areas of GBA”. This could be better explained\n",
    "-\tcould be better explanations on the image, and its inclusion\n",
    "\n",
    "**overall**\n",
    "-\trefining the questions would provide the reader a clearer idea as to the point behind the analyses\n",
    "-\tI really like how you modified the data frames to increase the clarity and readability for viewer\n",
    "-\tI would provide the reader a few more ways to understand the reasons behind your analysis choices (for example, including more mark down in certain areas, clear explanations on the ‘2018 aged care planning regions’ image, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback given to reviewer 2:\n",
    "\n",
    "**External:**\n",
    "- only sourced articles within this year, could create biases in the insights, and could reduce the overall analysis when identifying trends\n",
    "- LOVE the sentiment analysis on web titles \n",
    "- LOVE the dataframe containing the most frequent keyword amounts\n",
    "- LOVE the column displaying the polarity of the article, makes it easy to read\n",
    "\n",
    "**Internal:**\n",
    "- I like how you cleaned the original data frame to make it easier to read and used\n",
    "- I love the location analytics visualisations, they contain very important and relevant data\n",
    "\n",
    "**Overall:**\n",
    "- the data analysed is well presented, and utilised effectively\n",
    "- they need the data frames throughout the report makes it easier to read\n",
    "- your insights are well written and easy to understand\n",
    " \n",
    "- I would like to see the columns in the data frames renamed to further increase visibility\n",
    "- I would like to see some more markdown to have a better idea behind your thinking in each step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9808b2779335f0c2807c1ba1d02e59bcffca5136fddd2b56b75a42a062051586"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
